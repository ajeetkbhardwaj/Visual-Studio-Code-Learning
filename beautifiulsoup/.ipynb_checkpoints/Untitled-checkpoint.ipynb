{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd312b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8b8857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Code examples</title>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://keras.io/examples/\"\n",
    "req = requests.get(url)\n",
    "soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8e83ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "https://github.com/keras-team/keras\n",
      "/about/\n",
      "/getting_started/\n",
      "/guides/\n",
      "/api/\n",
      "/examples/\n",
      "/examples/vision/\n",
      "/examples/nlp/\n",
      "/examples/structured_data/\n",
      "/examples/timeseries/\n",
      "/examples/generative/\n",
      "/examples/audio/\n",
      "/examples/rl/\n",
      "/examples/graph/\n",
      "/examples/keras_recipes/\n",
      "/why_keras/\n",
      "/governance/\n",
      "/contributing/\n",
      "/keras_tuner/\n",
      "/keras_cv/\n",
      "/keras_nlp/\n",
      "https://colab.research.google.com/notebooks/welcome.ipynb\n",
      "/examples/vision/\n",
      "/examples/vision/image_classification_from_scratch\n",
      "/examples/vision/mnist_convnet\n",
      "/examples/vision/image_classification_efficientnet_fine_tuning\n",
      "/examples/vision/image_classification_with_vision_transformer\n",
      "/examples/vision/bit\n",
      "/examples/vision/attention_mil_classification\n",
      "/examples/vision/mlp_image_classification\n",
      "/examples/vision/mobilevit\n",
      "/examples/vision/xray_classification_with_tpus\n",
      "/examples/vision/cct\n",
      "/examples/vision/convmixer\n",
      "/examples/vision/eanet\n",
      "/examples/vision/involution\n",
      "/examples/vision/perceiver_image_classification\n",
      "/examples/vision/reptile\n",
      "/examples/vision/semisupervised_simclr\n",
      "/examples/vision/swin_transformers\n",
      "/examples/vision/vit_small_ds\n",
      "/examples/vision/shiftvit\n",
      "/examples/vision/oxford_pets_image_segmentation\n",
      "/examples/vision/deeplabv3_plus\n",
      "/examples/vision/retinanet\n",
      "/examples/vision/keypoint_detection\n",
      "/examples/vision/object_detection_using_vision_transformer\n",
      "/examples/vision/3D_image_classification\n",
      "/examples/vision/depth_estimation\n",
      "/examples/vision/nerf\n",
      "/examples/vision/pointnet\n",
      "/examples/vision/captcha_ocr\n",
      "/examples/vision/handwriting_recognition\n",
      "/examples/vision/autoencoder\n",
      "/examples/vision/mirnet\n",
      "/examples/vision/super_resolution_sub_pixel\n",
      "/examples/vision/edsr\n",
      "/examples/vision/zero_dce\n",
      "/examples/vision/cutmix\n",
      "/examples/vision/mixup\n",
      "/examples/vision/randaugment\n",
      "/examples/vision/image_captioning\n",
      "/examples/vision/nl_image_search\n",
      "/examples/vision/visualizing_what_convnets_learn\n",
      "/examples/vision/integrated_gradients\n",
      "/examples/vision/probing_vits\n",
      "/examples/vision/grad_cam\n",
      "/examples/vision/near_dup_search\n",
      "/examples/vision/semantic_image_clustering\n",
      "/examples/vision/siamese_contrastive\n",
      "/examples/vision/siamese_network\n",
      "/examples/vision/metric_learning\n",
      "/examples/vision/metric_learning_tf_similarity\n",
      "/examples/vision/video_classification\n",
      "/examples/vision/conv_lstm\n",
      "/examples/vision/video_transformers\n",
      "/examples/vision/vivit\n",
      "/examples/vision/adamatch\n",
      "/examples/vision/barlow_twins\n",
      "/examples/vision/cait\n",
      "/examples/vision/consistency_training\n",
      "/examples/vision/deit\n",
      "/examples/vision/fixres\n",
      "/examples/vision/gradient_centralization\n",
      "/examples/vision/knowledge_distillation\n",
      "/examples/vision/learnable_resizer\n",
      "/examples/vision/masked_image_modeling\n",
      "/examples/vision/nnclr\n",
      "/examples/vision/patch_convnet\n",
      "/examples/vision/pointnet_segmentation\n",
      "/examples/vision/simsiam\n",
      "/examples/vision/supervised-contrastive-learning\n",
      "/examples/vision/token_learner\n",
      "/examples/nlp/\n",
      "/examples/nlp/text_classification_from_scratch\n",
      "/examples/nlp/active_learning_review_classification\n",
      "/examples/nlp/fnet_classification_with_keras_nlp\n",
      "/examples/nlp/multi_label_classification\n",
      "/examples/nlp/text_classification_with_transformer\n",
      "/examples/nlp/text_classification_with_switch_transformer\n",
      "/examples/nlp/tweet-classification-using-tfdf\n",
      "/examples/nlp/pretrained_word_embeddings\n",
      "/examples/nlp/bidirectional_lstm_imdb\n",
      "/examples/nlp/neural_machine_translation_with_keras_nlp\n",
      "/examples/nlp/neural_machine_translation_with_transformer\n",
      "/examples/nlp/lstm_seq2seq\n",
      "/examples/nlp/multimodal_entailment\n",
      "/examples/nlp/ner_transformers\n",
      "/examples/nlp/text_extraction_with_bert\n",
      "/examples/nlp/addition_rnn\n",
      "/examples/nlp/semantic_similarity_with_bert\n",
      "/examples/nlp/masked_language_modeling\n",
      "/examples/nlp/pretraining_BERT\n",
      "/examples/nlp/question_answering\n",
      "/examples/nlp/t5_hf_summarization\n",
      "/examples/structured_data/\n",
      "/examples/structured_data/structured_data_classification_with_feature_space\n",
      "/examples/structured_data/imbalanced_classification\n",
      "/examples/structured_data/structured_data_classification_from_scratch\n",
      "/examples/structured_data/wide_deep_cross_networks\n",
      "/examples/structured_data/bayesian_neural_networks\n",
      "/examples/structured_data/classification_with_grn_and_vsn\n",
      "/examples/structured_data/classification_with_tfdf\n",
      "/examples/structured_data/deep_neural_decision_forests\n",
      "/examples/structured_data/tabtransformer\n",
      "/examples/structured_data/collaborative_filtering_movielens\n",
      "/examples/structured_data/movielens_recommendations_transformers\n",
      "/examples/timeseries/\n",
      "/examples/timeseries/timeseries_classification_from_scratch\n",
      "/examples/timeseries/timeseries_classification_transformer\n",
      "/examples/timeseries/eeg_signal_classification\n",
      "/examples/timeseries/timeseries_anomaly_detection\n",
      "/examples/timeseries/timeseries_traffic_forecasting\n",
      "/examples/timeseries/timeseries_weather_forecasting\n",
      "/examples/generative/\n",
      "/examples/generative/ddim\n",
      "/examples/generative/random_walks_with_stable_diffusion\n",
      "/examples/generative/vae\n",
      "/examples/generative/dcgan_overriding_train_step\n",
      "/examples/generative/wgan_gp\n",
      "/examples/generative/conditional_gan\n",
      "/examples/generative/cyclegan\n",
      "/examples/generative/gan_ada\n",
      "/examples/generative/deep_dream\n",
      "/examples/generative/gaugan\n",
      "/examples/generative/pixelcnn\n",
      "/examples/generative/stylegan\n",
      "/examples/generative/vq_vae\n",
      "/examples/generative/neural_style_transfer\n",
      "/examples/generative/adain\n",
      "/examples/generative/text_generation_gpt\n",
      "/examples/generative/text_generation_with_miniature_gpt\n",
      "/examples/generative/lstm_character_level_text_generation\n",
      "/examples/generative/text_generation_fnet\n",
      "/examples/generative/molecule_generation\n",
      "/examples/generative/wgan-graphs\n",
      "/examples/generative/real_nvp\n",
      "/examples/audio/\n",
      "/examples/audio/ctc_asr\n",
      "/examples/audio/melgan_spectrogram_inversion\n",
      "/examples/audio/speaker_recognition_using_cnn\n",
      "/examples/audio/transformer_asr\n",
      "/examples/audio/uk_ireland_accent_recognition\n",
      "/examples/audio/wav2vec2_audiocls\n",
      "/examples/rl/\n",
      "/examples/rl/actor_critic_cartpole\n",
      "/examples/rl/ddpg_pendulum\n",
      "/examples/rl/deep_q_network_breakout\n",
      "/examples/rl/ppo_cartpole\n",
      "/examples/graph/\n",
      "/examples/graph/gat_node_classification\n",
      "/examples/graph/gnn_citations\n",
      "/examples/graph/mpnn-molecular-graphs\n",
      "/examples/graph/node2vec_movielens\n",
      "/examples/keras_recipes/\n",
      "/examples/keras_recipes/antirectifier\n",
      "/examples/keras_recipes/bayesian_neural_networks\n",
      "/examples/keras_recipes/better_knowledge_distillation\n",
      "/examples/keras_recipes/creating_tfrecords\n",
      "/examples/keras_recipes/debugging_tips\n",
      "/examples/keras_recipes/endpoint_layer_pattern\n",
      "/examples/keras_recipes/memory_efficient_embeddings\n",
      "/examples/keras_recipes/quasi_svm\n",
      "/examples/keras_recipes/sample_size_estimate\n",
      "/examples/keras_recipes/sklearn_metric_callbacks\n",
      "/examples/keras_recipes/subclassing_conv_layers\n",
      "/examples/keras_recipes/tensorflow_numpy_models\n",
      "/examples/keras_recipes/tfrecord\n",
      "/examples/keras_recipes/trainer_pattern\n",
      "https://github.com/keras-team/keras-io\n",
      "https://github.com/keras-team/keras-io/blob/master/README.md\n",
      "#code-examples\n",
      "#adding-a-new-code-example\n",
      "https://policies.google.com/terms\n",
      "https://policies.google.com/privacy\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff3d23be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Computer Vision</title>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://keras.io/examples/vision/\"\n",
    "req = requests.get(url)\n",
    "soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a90ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "https://github.com/keras-team/keras\n",
      "/about/\n",
      "/getting_started/\n",
      "/guides/\n",
      "/api/\n",
      "/examples/\n",
      "/examples/vision/\n",
      "/examples/vision/image_classification_from_scratch/\n",
      "/examples/vision/mnist_convnet/\n",
      "/examples/vision/image_classification_efficientnet_fine_tuning/\n",
      "/examples/vision/image_classification_with_vision_transformer/\n",
      "/examples/vision/bit/\n",
      "/examples/vision/attention_mil_classification/\n",
      "/examples/vision/mlp_image_classification/\n",
      "/examples/vision/mobilevit/\n",
      "/examples/vision/xray_classification_with_tpus/\n",
      "/examples/vision/cct/\n",
      "/examples/vision/convmixer/\n",
      "/examples/vision/eanet/\n",
      "/examples/vision/involution/\n",
      "/examples/vision/perceiver_image_classification/\n",
      "/examples/vision/reptile/\n",
      "/examples/vision/semisupervised_simclr/\n",
      "/examples/vision/swin_transformers/\n",
      "/examples/vision/vit_small_ds/\n",
      "/examples/vision/shiftvit/\n",
      "/examples/vision/oxford_pets_image_segmentation/\n",
      "/examples/vision/deeplabv3_plus/\n",
      "/examples/vision/retinanet/\n",
      "/examples/vision/keypoint_detection/\n",
      "/examples/vision/object_detection_using_vision_transformer/\n",
      "/examples/vision/3D_image_classification/\n",
      "/examples/vision/depth_estimation/\n",
      "/examples/vision/nerf/\n",
      "/examples/vision/pointnet/\n",
      "/examples/vision/captcha_ocr/\n",
      "/examples/vision/handwriting_recognition/\n",
      "/examples/vision/autoencoder/\n",
      "/examples/vision/mirnet/\n",
      "/examples/vision/super_resolution_sub_pixel/\n",
      "/examples/vision/edsr/\n",
      "/examples/vision/zero_dce/\n",
      "/examples/vision/cutmix/\n",
      "/examples/vision/mixup/\n",
      "/examples/vision/randaugment/\n",
      "/examples/vision/image_captioning/\n",
      "/examples/vision/nl_image_search/\n",
      "/examples/vision/visualizing_what_convnets_learn/\n",
      "/examples/vision/integrated_gradients/\n",
      "/examples/vision/probing_vits/\n",
      "/examples/vision/grad_cam/\n",
      "/examples/vision/near_dup_search/\n",
      "/examples/vision/semantic_image_clustering/\n",
      "/examples/vision/siamese_contrastive/\n",
      "/examples/vision/siamese_network/\n",
      "/examples/vision/metric_learning/\n",
      "/examples/vision/metric_learning_tf_similarity/\n",
      "/examples/vision/video_classification/\n",
      "/examples/vision/conv_lstm/\n",
      "/examples/vision/video_transformers/\n",
      "/examples/vision/vivit/\n",
      "/examples/vision/adamatch/\n",
      "/examples/vision/barlow_twins/\n",
      "/examples/vision/cait/\n",
      "/examples/vision/consistency_training/\n",
      "/examples/vision/deit/\n",
      "/examples/vision/fixres/\n",
      "/examples/vision/gradient_centralization/\n",
      "/examples/vision/knowledge_distillation/\n",
      "/examples/vision/learnable_resizer/\n",
      "/examples/vision/masked_image_modeling/\n",
      "/examples/vision/nnclr/\n",
      "/examples/vision/patch_convnet/\n",
      "/examples/vision/pointnet_segmentation/\n",
      "/examples/vision/simsiam/\n",
      "/examples/vision/supervised-contrastive-learning/\n",
      "/examples/vision/token_learner/\n",
      "/examples/nlp/\n",
      "/examples/structured_data/\n",
      "/examples/timeseries/\n",
      "/examples/generative/\n",
      "/examples/audio/\n",
      "/examples/rl/\n",
      "/examples/graph/\n",
      "/examples/keras_recipes/\n",
      "/why_keras/\n",
      "/governance/\n",
      "/contributing/\n",
      "/keras_tuner/\n",
      "/keras_cv/\n",
      "/keras_nlp/\n",
      "/examples\n",
      "/examples/vision/\n",
      "/examples/vision/image_classification_from_scratch\n",
      "/examples/vision/mnist_convnet\n",
      "/examples/vision/image_classification_efficientnet_fine_tuning\n",
      "/examples/vision/image_classification_with_vision_transformer\n",
      "/examples/vision/bit\n",
      "/examples/vision/attention_mil_classification\n",
      "/examples/vision/mlp_image_classification\n",
      "/examples/vision/mobilevit\n",
      "/examples/vision/xray_classification_with_tpus\n",
      "/examples/vision/cct\n",
      "/examples/vision/convmixer\n",
      "/examples/vision/eanet\n",
      "/examples/vision/involution\n",
      "/examples/vision/perceiver_image_classification\n",
      "/examples/vision/reptile\n",
      "/examples/vision/semisupervised_simclr\n",
      "/examples/vision/swin_transformers\n",
      "/examples/vision/vit_small_ds\n",
      "/examples/vision/shiftvit\n",
      "/examples/vision/oxford_pets_image_segmentation\n",
      "/examples/vision/deeplabv3_plus\n",
      "/examples/vision/retinanet\n",
      "/examples/vision/keypoint_detection\n",
      "/examples/vision/object_detection_using_vision_transformer\n",
      "/examples/vision/3D_image_classification\n",
      "/examples/vision/depth_estimation\n",
      "/examples/vision/nerf\n",
      "/examples/vision/pointnet\n",
      "/examples/vision/captcha_ocr\n",
      "/examples/vision/handwriting_recognition\n",
      "/examples/vision/autoencoder\n",
      "/examples/vision/mirnet\n",
      "/examples/vision/super_resolution_sub_pixel\n",
      "/examples/vision/edsr\n",
      "/examples/vision/zero_dce\n",
      "/examples/vision/cutmix\n",
      "/examples/vision/mixup\n",
      "/examples/vision/randaugment\n",
      "/examples/vision/image_captioning\n",
      "/examples/vision/nl_image_search\n",
      "/examples/vision/visualizing_what_convnets_learn\n",
      "/examples/vision/integrated_gradients\n",
      "/examples/vision/probing_vits\n",
      "/examples/vision/grad_cam\n",
      "/examples/vision/near_dup_search\n",
      "/examples/vision/semantic_image_clustering\n",
      "/examples/vision/siamese_contrastive\n",
      "/examples/vision/siamese_network\n",
      "/examples/vision/metric_learning\n",
      "/examples/vision/metric_learning_tf_similarity\n",
      "/examples/vision/video_classification\n",
      "/examples/vision/conv_lstm\n",
      "/examples/vision/video_transformers\n",
      "/examples/vision/vivit\n",
      "/examples/vision/adamatch\n",
      "/examples/vision/barlow_twins\n",
      "/examples/vision/cait\n",
      "/examples/vision/consistency_training\n",
      "/examples/vision/deit\n",
      "/examples/vision/fixres\n",
      "/examples/vision/gradient_centralization\n",
      "/examples/vision/knowledge_distillation\n",
      "/examples/vision/learnable_resizer\n",
      "/examples/vision/masked_image_modeling\n",
      "/examples/vision/nnclr\n",
      "/examples/vision/patch_convnet\n",
      "/examples/vision/pointnet_segmentation\n",
      "/examples/vision/simsiam\n",
      "/examples/vision/supervised-contrastive-learning\n",
      "/examples/vision/token_learner\n",
      "https://policies.google.com/terms\n",
      "https://policies.google.com/privacy\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805b2dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p>data</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "with open(\"Features of R Programming that will make you obsessed with R Language! - DataFlair.html\") as fp:\n",
    "    soup = BeautifulSoup(fp)\n",
    "soup = BeautifulSoup(\"<html>data<html>\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988fa325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><b>Ajeet Kumar</b>, <i>&amp; web scraping for data science;</i></body></html>\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "html = '''<b>Ajeet Kumar</b>, <i>& web scraping for data science;</i>'''\n",
    "soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0b4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
